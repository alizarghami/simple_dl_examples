{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lax0-ow7ylPS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "model_path = 'models/model.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "sdoVqW8H4Rpg",
    "outputId": "061bb8c5-4d3c-4e60-e8bc-34905e5a1391"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "EPOCH_NUMBER = 10\n",
    "\n",
    "t = tf.placeholder(tf.bool, name='IfTrain_placeholder')                                                     # if we are in training phase\n",
    "X = tf.placeholder(dtype=tf.float32, shape=[None, 28, 28, 1], name='Data_placeholder')\n",
    "y = tf.placeholder(dtype=tf.int32, shape=[None], name='Label_placeholder')\n",
    "\n",
    "X_data = tf.data.Dataset.from_tensor_slices(X).batch(BATCH_SIZE)\n",
    "y_data = tf.data.Dataset.from_tensor_slices(y).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y40owpgehRX3"
   },
   "outputs": [],
   "source": [
    "X_iter = X_data.make_initializable_iterator()\n",
    "X_batch = X_iter.get_next()\n",
    "\n",
    "y_iter = y_data.make_initializable_iterator()\n",
    "y_batch = y_iter.get_next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GkqurGpl0quN"
   },
   "outputs": [],
   "source": [
    "oh_y = tf.one_hot(indices=y_batch, depth=10)\n",
    "\n",
    "c1 = tf.layers.conv2d(inputs=X_batch, \n",
    "                      filters=32, \n",
    "                      kernel_size=[5,5], \n",
    "                      padding='same', \n",
    "                      activation=tf.nn.relu, \n",
    "                      name='CNN1')\n",
    "\n",
    "m1 = tf.layers.max_pooling2d(inputs=c1, \n",
    "                             pool_size=[2,2], \n",
    "                             strides=2, \n",
    "                             padding='same',\n",
    "                             name='MaxPool1')\n",
    "\n",
    "c2 = tf.layers.conv2d(inputs=m1, \n",
    "                      filters=64, \n",
    "                      kernel_size=[5,5], \n",
    "                      padding='same', \n",
    "                      activation=tf.nn.relu, \n",
    "                      name='CNN2')\n",
    "\n",
    "m2 = tf.layers.max_pooling2d(inputs=c2, \n",
    "                             pool_size=[2,2], \n",
    "                             strides=2, \n",
    "                             padding='same', \n",
    "                             name='MaxPool2')\n",
    "\n",
    "f1 = tf.reshape(tensor=m2, shape=[-1, 7*7*64], name='Flat1')\n",
    "\n",
    "d1 = tf.layers.dense(inputs=f1, \n",
    "                     units=1024,\n",
    "                     activation=tf.nn.relu,\n",
    "                     name='Dense1')\n",
    "\n",
    "dr1 = tf.layers.dropout(inputs=d1, rate=0.4, training=t, name='Dropout1')\n",
    "\n",
    "d2 = tf.layers.dense(inputs=dr1, \n",
    "                     units=10, \n",
    "                     name='Dense2')\n",
    "\n",
    "loss = tf.losses.softmax_cross_entropy(onehot_labels=oh_y, logits=d2)\n",
    "classes = tf.argmax(input=d2, axis=1, name='ArgMax1')\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mXL6M2cg3p5h"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.003, name='GD1')\n",
    "train_op = optimizer.minimize(loss=loss, global_step=tf.train.get_global_step(), name='Optimizer1')\n",
    "\n",
    "guess = tf.nn.softmax(d2)\n",
    "is_correct = tf.equal(tf.argmax(guess, 1), tf.argmax(oh_y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "id": "qdokC0BI32rc",
    "outputId": "620e7bea-2e44-40ad-92d3-1f7628f20d5d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "X_train = np.reshape(mnist.train.images, (-1, 28, 28, 1))\n",
    "y_train = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "X_test = np.reshape(mnist.test.images, (-1, 28, 28, 1))\n",
    "y_test = np.asarray(mnist.test.labels, dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 9367
    },
    "id": "3ialVMz8hniv",
    "outputId": "0beb3812-fe5a-45de-88dc-815143d356d1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    # Training\n",
    "    for e in tqdm(range(EPOCH_NUMBER)):\n",
    "        sess.run(X_iter.initializer, feed_dict={X:X_train})\n",
    "        sess.run(y_iter.initializer, feed_dict={y:y_train})\n",
    "  \n",
    "        while True:\n",
    "            try:\n",
    "                out = sess.run({'accuracy': accuracy, 'loss': loss, 'train optimizer': train_op}, feed_dict={t:True})\n",
    "\n",
    "                losses.append(out['loss'])\n",
    "                train_accuracies.append(out['accuracy'])\n",
    "            except:\n",
    "                break\n",
    "    saver.save(sess, model_path)\n",
    "                \n",
    "    # Evaluation            \n",
    "    sess.run(X_iter.initializer, feed_dict={X:X_test})\n",
    "    sess.run(y_iter.initializer, feed_dict={y:y_test})\n",
    "  \n",
    "    while True:\n",
    "        try:\n",
    "            out = sess.run({'accuracy': accuracy, 'loss': loss}, feed_dict={t:False})\n",
    "            test_accuracies.append(out['accuracy'])\n",
    "        except:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_loss = []\n",
    "ave_acc = []\n",
    "for i in range(100,len(losses)):\n",
    "    ave_loss.append(np.mean(losses[i-100:i]))\n",
    "    ave_acc.append(np.mean(train_accuracies[i-100:i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(ave_loss)\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Loss')\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(ave_acc)\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "\n",
    "print('Average test accuracy is %{:.2}'.format(100*np.mean(test_accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "new_mnist.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
